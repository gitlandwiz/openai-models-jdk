/**
* OpenAI API
* APIs for sampling from and fine-tuning language models
*
* The version of the OpenAPI document: 1.2.0
* 
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
package org.openapitools.client.models

import org.openapitools.client.models.AnyType
import org.openapitools.client.models.OneOfLessThanStringCommaArrayGreaterThan

import com.squareup.moshi.Json

/**
 * 
 * @param model ID of the model to use for completion. You can select one of `ada`, `babbage`, `curie`, or `davinci`.
 * @param question Question to get answered.
 * @param examples List of (question, answer) pairs that will help steer the model towards the tone and answer format you'd like. We recommend adding 2 to 3 examples.
 * @param examplesContext A text snippet containing the contextual information used to generate the answers for the `examples` you provide.
 * @param documents List of documents from which the answer for the input `question` should be derived. If this is an empty list, the question will be answered based on the question-answer examples.  You should specify either `documents` or a `file`, but not both. 
 * @param file The ID of an uploaded file that contains documents to search over. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.  You should specify either `documents` or a `file`, but not both. 
 * @param searchModel ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`.
 * @param maxRerank The maximum number of documents to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost.
 * @param temperature What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
 * @param logprobs Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.  The maximum value for `logprobs` is 5. If you need more than this, please contact us through our [Help center](https://help.openai.com) and describe your use case.  When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs. 
 * @param maxTokens The maximum number of tokens allowed for the generated answer
 * @param stop completions_stop_description
 * @param n How many answers to generate for each question.
 * @param returnPrompt If set to `true`, the returned JSON will include a \"prompt\" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.
 * @param expand If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support `completion` and `file` objects for expansion.
 */

data class CreateAnswerRequest (
    /* ID of the model to use for completion. You can select one of `ada`, `babbage`, `curie`, or `davinci`. */
    @Json(name = "model")
    val model: kotlin.String,
    /* Question to get answered. */
    @Json(name = "question")
    val question: kotlin.String,
    /* List of (question, answer) pairs that will help steer the model towards the tone and answer format you'd like. We recommend adding 2 to 3 examples. */
    @Json(name = "examples")
    val examples: kotlin.collections.List<kotlin.collections.List<kotlin.String>>,
    /* A text snippet containing the contextual information used to generate the answers for the `examples` you provide. */
    @Json(name = "examples_context")
    val examplesContext: kotlin.String,
    /* List of documents from which the answer for the input `question` should be derived. If this is an empty list, the question will be answered based on the question-answer examples.  You should specify either `documents` or a `file`, but not both.  */
    @Json(name = "documents")
    val documents: kotlin.collections.List<kotlin.String>? = null,
    /* The ID of an uploaded file that contains documents to search over. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.  You should specify either `documents` or a `file`, but not both.  */
    @Json(name = "file")
    val file: kotlin.String? = null,
    /* ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`. */
    @Json(name = "search_model")
    val searchModel: kotlin.String? = null,
    /* The maximum number of documents to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost. */
    @Json(name = "max_rerank")
    val maxRerank: kotlin.Int? = null,
    /* What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. */
    @Json(name = "temperature")
    val temperature: java.math.BigDecimal? = null,
    /* Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.  The maximum value for `logprobs` is 5. If you need more than this, please contact us through our [Help center](https://help.openai.com) and describe your use case.  When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs.  */
    @Json(name = "logprobs")
    val logprobs: kotlin.Int? = null,
    /* The maximum number of tokens allowed for the generated answer */
    @Json(name = "max_tokens")
    val maxTokens: kotlin.Int? = null,
    /* completions_stop_description */
    @Json(name = "stop")
    val stop: OneOfLessThanStringCommaArrayGreaterThan? = null,
    /* How many answers to generate for each question. */
    @Json(name = "n")
    val n: kotlin.Int? = null,
    /* If set to `true`, the returned JSON will include a \"prompt\" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes. */
    @Json(name = "return_prompt")
    val returnPrompt: kotlin.Boolean? = null,
    /* If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support `completion` and `file` objects for expansion. */
    @Json(name = "expand")
    val expand: kotlin.collections.List<AnyType>? = null
)

